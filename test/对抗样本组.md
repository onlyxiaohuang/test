## 对抗样本组(ADV)

对抗样本是一个十分火热的研究领域，涉及到神经网络的鲁棒性、可解释性、泛化性等十分重要的问题，是AI安全的重要研究内容之一。

#### 论文阅读

- [ ] 对抗攻击

- [Intriguing properties of neural networks](https://arxiv.org/abs/1312.6199v4)（最早的对抗，可选读或不读）

- [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572v3)

- [Reliable Evaluation of Adversarial Robustness with an Ensemble of Diverse Parameter-free Attacks](https://link.zhihu.com/?target=http%3A//arxiv.org/abs/2003.01690)（auto-attack 对抗攻击目前普遍被采用的sota）

- 以下可选读或不读
  
  - [Boosting Adversarial Attacks with Momentum](https://arxiv.org/abs/1710.06081v3)
  - [Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors](https://arxiv.org/abs/1807.07978v3)
  - [Black-box Adversarial Attacks with Limited Queries and Information](https://arxiv.org/abs/1804.08598v3)

- [ ] 对抗防御

- [Towards Deep Learning Models Resistant to Adversarial Attacks](https://arxiv.org/abs/1706.06083v4) （这一篇相当于是在对抗攻击和对抗防御一起取得了SOTA，很重要）

- [Theoretically Principled Trade-off between Robustness and Accuracy](https://arxiv.org/abs/1901.08573v3)

- 以下是可证明式防御，和普通的对抗防御是很大程度上不同的另一条路，可选读或不读
  
  - [On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models](https://arxiv.org/abs/1810.12715v4)
  - [Towards Stable and Efficient Training of Verifiably Robust Neural Networks](https://arxiv.org/abs/1906.06316)

论文内容涉及到白盒攻击、迁移攻击、查询攻击、对抗训练、特征去噪、可证明防御等内容。

以上10篇论文均是图像识别领域的对抗攻防问题，与在CV领域输入是连续的RGB值不同，在NLP领域输入是离散的单词序列，所以对抗攻击的定义也会有所不同，下面列举了一些NLP对抗攻击的论文：

- [ ] 文本对抗攻击

- [Generating Natural Language Adversarial Examples.](http://arxiv.org/abs/1804.07998)

- [Word-level Textual Adversarial Attacking as Combinatorial Optimization.](https://aclanthology.org/2020.acl-main.540) 

- [Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment.](http://arxiv.org/abs/1907.11932)

- [Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency](https://aclanthology.org/P19-1103/)

此处仅作一些列举，另外可关注[thunlp/TAADpapers: Must-read Papers on Textual Adversarial Attack and Defense ](https://github.com/thunlp/TAADpapers)

  

  阅读这些文章后，根据你的理解，适当实现其中部分算法或模型。

​    在目标检测、点云、机器翻译等领域也存在对抗样本的安全隐患。因此我们欢迎同学们自己搜索感兴趣的文献进行阅读和复现，进行你自己的思考。这里的论文只做推荐，而不做硬性要求。但希望你在答辩日有丰厚的成果展示。

#### 竞赛推荐

​    对抗方面的竞赛较少，暂时没有找到对抗方面正在进行的竞赛，但可关注[阿里安全挑战者计划](https://s.alibaba.com/challenge)，每年不定时开启新一轮竞赛。

#### 科研

​    科研是一个很大的话题；在真正投身科研之前，往往需要大量的学习和探索，打下基础，思考方向。

​    但由于我们的第二轮测试仅仅提供了一个月的时间，因此，如果有同学更加希望参加科研方向的工作，我们提出以下要求：

- 对你的学习做适当记录，强烈建议使用电子记录，如第一轮中建议的Typora + LaTeX
- 不能仅仅阅读上述推荐的论文，而应当有更加发散的论文阅读
- 对模型和算法理解后，可以复现的，选择性地进行复现
